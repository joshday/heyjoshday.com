<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <link rel=stylesheet  href="/css/style.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/assets/favicon.png"> <title>JuliaML Basics</title> <script async defer src="https://buttons.github.io/buttons.js"></script> <link rel=stylesheet  href="https://rsms.me/inter/inter.css"> <script src="/libs/lunr/lunr.min.js"></script> <script src="/libs/lunr/lunr_index.js"></script> <script src="/libs/lunr/lunrclient.min.js"></script> <div class=sidebar > <div class=sidebar-item  style="text-align:center;"> <a href="https://twitter.com/heyjoshday?ref_src=twsrc%5Etfw" class=twitter-follow-button  data-show-count=false >Follow @heyjoshday</a><script async src="https://platform.twitter.com/widgets.js" charset=utf-8 ></script> <br> <a href="https://twitter.com/JuliaForDataSci?ref_src=twsrc%5Etfw" class=twitter-follow-button  data-show-count=false >Follow @JuliaForDataSci</a><script async src="https://platform.twitter.com/widgets.js" charset=utf-8 ></script> <br> <a class=github-button  href="https://github.com/sponsors/joshday" data-icon=octicon-heart  aria-label="Sponsor @joshday on GitHub">Sponsor</a> </div> <div class=sidebar-about > <a href="/"><img src="/assets/gh.jpeg" style="border-radius:50%; width: 150px; margin-top: 50px; margin: auto;"><h2 style="color:white;">Dr. Josh Day</h2></a> <p class="lead center-child" style="text-align: left; margin-top: 25px;"> <a href="https://julialang.org/" target=_blank  rel=noreferrer  style="color: #FFFFFF80;">#JuliaLang</a> <br> #DataScience <br> #DataViz <br> #Statistics </p> </div> <div class=sidebar-item > <nav class=sidebar-nav  style="border-top: 1px solid #FFFFFF20; border-bottom: 1px solid #FFFFFF20;"> <a class="sidebar-nav-item " href="/">Home</a> <a class="sidebar-nav-item active" href="/blog/">Blog</a> </nav> </div> <div class="sidebar-item sidebar-sticky"> <form id=lunrSearchForm  name=lunrSearchForm > <input class=search-input  id=searchbox  name=q  placeholder=Search  type=text , style="background: #FFFFFF20;"> <input class=btn  type=submit  value=Search  formaction="/search/index.html" style="visibility: hidden"> </form> </div> </div> <div class="content container"> <div class=franklin-content ><h1 id=juliaml_basics ><a href="#juliaml_basics" class=header-anchor >JuliaML Basics</a></h1> <img src="https://avatars3.githubusercontent.com/u/15799035?v=3&s=200" style="width: 20%; margin:auto; border-radius: 5px"> <p><a href="https://github.com/JuliaML">JuliaML</a> is a GitHub organization dedicated to building tools for machine learning in Julia. This post serves as an introduction to some of the building blocks which JuliaML provides. The two packages I&#39;ll discuss here are:</p> <ul> <li><p><a href="https://github.com/JuliaML/LossFunctions.jl">LossFunctions.jl</a></p> <li><p><a href="https://github.com/JuliaML/PenaltyFunctions.jl">PenaltyFunctions.jl</a></p> </ul> <p>I&#39;m assuming you have a little background in statistics/machine learning and an objective function such as</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><mi mathvariant=normal >_</mi><msup><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msup><mi>f</mi><mi mathvariant=normal >_</mi><mi>i</mi><mo stretchy=false >(</mo><mi>β</mi><mo stretchy=false >)</mo><mo>+</mo><mo>∑</mo><mi mathvariant=normal >_</mi><msup><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></msup><mi>λ</mi><mi mathvariant=normal >_</mi><mi>j</mi><mi>J</mi><mo stretchy=false >(</mo><mi>β</mi><mi mathvariant=normal >_</mi><mi>j</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">\frac{1}{n}\sum\_{i=1}^n f\_i(\beta)+\sum\_{j=1}^p \lambda\_j J(\beta\_j)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.0074em;vertical-align:-0.686em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3214em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mop op-symbol large-op" style="position:relative;top:0em;">∑</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class=mord ><span class="mord mathnormal">i</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord >1</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1.6em;vertical-align:-0.55em;"></span><span class="mop op-symbol large-op" style="position:relative;top:0em;">∑</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class=mord ><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord >1</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span><span class="mord mathnormal">λ</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class=mclose >)</span></span></span></span></span> <p>is recognizable to you as a &quot;loss&quot; &#43; &quot;penalty&quot;.</p> <h1 id=lossfunctionsjl ><a href="#lossfunctionsjl" class=header-anchor >LossFunctions.jl</a></h1> <p>An interface for dealing with loss functions. Internally, most losses are defined as distance-based &#40;a function of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent=true ><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">\hat y-y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.6944em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=accent-body  style="left:-0.1944em;"><span class=mord >^</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1944em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>&#41; or margin-based &#40;a function of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∗</mo><mover accent=true ><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">y * \hat y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6597em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >∗</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.6944em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=accent-body  style="left:-0.1944em;"><span class=mord >^</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>&#41; where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> is the target and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent=true ><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.6944em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=accent-body  style="left:-0.1944em;"><span class=mord >^</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> is a predicted value.</p> <h4 id=distance-based_losses ><a href="#distance-based_losses" class=header-anchor >Distance-based losses</a></h4> <p><img src="https://camo.githubusercontent.com/80ae72e5878d98aacb0eed6863958c02fd73b1b3/68747470733a2f2f7261776769746875622e636f6d2f4a756c69614d4c2f46696c6553746f726167652f6d61737465722f4c6f737346756e6374696f6e732f64697374616e63652e737667" alt="" /></p> <h4 id=margin-based_losses ><a href="#margin-based_losses" class=header-anchor >Margin-based losses</a></h4> <p><img src="https://camo.githubusercontent.com/80dc81d308845dd34ff70a953aafffb30b2c5c3a/68747470733a2f2f7261776769746875622e636f6d2f4a756c69614d4c2f46696c6553746f726167652f6d61737465722f4c6f737346756e6374696f6e732f6d617267696e2e737667" alt="" /></p> <h3 id=example_usage ><a href="#example_usage" class=header-anchor >Example Usage</a></h3> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> LossFunctions

l = L1DistLoss()
value(l, <span class=hljs-number >.1</span>, <span class=hljs-number >.2</span>)  <span class=hljs-comment ># |.2 - .1|</span>
deriv(l, <span class=hljs-number >.1</span>, <span class=hljs-number >.2</span>)  <span class=hljs-comment ># sign(.2 - .1)</span>

y = randn(<span class=hljs-number >100</span>)
yhat = randn(<span class=hljs-number >100</span>)

value(l, y, yhat)  <span class=hljs-comment ># vector of value mapped to y[i], yhat[i]</span>
value(l, y, yhat, AvgMode.Sum())  <span class=hljs-comment ># sum(value(l, y, yhat)), but better</span>
value(l, y, yhat, AvgModel.Mean()) <span class=hljs-comment ># mean(value(l, y, yhat)), but better</span></code></pre> <h4 id=naive_gradient_descent_algorithm ><a href="#naive_gradient_descent_algorithm" class=header-anchor >Naive Gradient Descent Algorithm</a></h4> <p>Assume we want to use a linear transformation so that our prediction of a vector <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mi>β</mi></mrow><annotation encoding="application/x-tex">X\beta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">Xβ</span></span></span></span>.</p> <p>Our loss function looks like</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><mi mathvariant=normal >_</mi><msup><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msup><mi>f</mi><mo stretchy=false >(</mo><mi>y</mi><mi mathvariant=normal >_</mi><mi>i</mi><mo separator=true >,</mo><mi>x</mi><mi mathvariant=normal >_</mi><msup><mi>i</mi><mi>T</mi></msup><mi>β</mi><mo stretchy=false >)</mo><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> \frac{1}{n}\sum\_{i=1}^n f(y\_i, x\_i^T\beta), </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.0074em;vertical-align:-0.686em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3214em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mop op-symbol large-op" style="position:relative;top:0em;">∑</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class=mord ><span class="mord mathnormal">i</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord >1</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class="mord mathnormal">i</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=mclose >)</span><span class=mpunct >,</span></span></span></span></span> <p>with gradient</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msup><mi>X</mi><mi>T</mi></msup><mo stretchy=false >[</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mi>f</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup><mo stretchy=false >(</mo><mi>y</mi><mi mathvariant=normal >_</mi><mi>i</mi><mo separator=true >,</mo><mi>x</mi><mi mathvariant=normal >_</mi><msup><mi>i</mi><mi>T</mi></msup><mi>β</mi><mo stretchy=false >)</mo><mo stretchy=false >]</mo><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> X^T[\frac{1}{n}\sum_{i=1}^n f&#x27;(y\_i, x\_i^T\beta)]. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.9291em;vertical-align:-1.2777em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class=mopen >[</span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3214em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.2777em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathnormal">i</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class="mord mathnormal">i</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=mclose >)]</span><span class=mord >.</span></span></span></span></span> <p>We can implement a naive, inefficient gradient descent algorithm as:</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> f(l::Loss, x::<span class=hljs-built_in >Matrix</span>, y::<span class=hljs-built_in >Vector</span>; maxit=<span class=hljs-number >20</span>, s=<span class=hljs-number >.5</span>)
    n, p = size(x)
    β = zeros(p)
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:maxit
        β -= (s / n) * x&#x27; * deriv(l, y, x * β)
    <span class=hljs-keyword >end</span>
    β
<span class=hljs-keyword >end</span></code></pre> <p>This automatically works with whatever loss function I provide because multiple dispatch is amazing:</p> <pre><code class="julia hljs"><span class=hljs-comment ># make some fake data</span>
x = randn(<span class=hljs-number >1000</span>, <span class=hljs-number >3</span>)
y = x * [<span class=hljs-number >1.0</span>, <span class=hljs-number >2.0</span>, <span class=hljs-number >3.0</span>] + randn(<span class=hljs-number >1000</span>)</code></pre> <pre><code class="julia hljs">julia&gt; f(L2DistLoss(), x, y)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.966367</span>
 <span class=hljs-number >2.05046</span>
 <span class=hljs-number >2.94227</span>

julia&gt; f(L1DistLoss(), x, y)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >1.00185</span>
 <span class=hljs-number >2.00302</span>
 <span class=hljs-number >2.95002</span>

julia&gt; f(HuberLoss(<span class=hljs-number >2.</span>), x, y)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.967642</span>
 <span class=hljs-number >2.0485</span>
 <span class=hljs-number >2.94429</span></code></pre> <h1 id=penaltyfunctionsjl ><a href="#penaltyfunctionsjl" class=header-anchor >PenaltyFunctions.jl</a></h1> <p>An interface for penalty/regularization functions. It follows similar conventions to LossFunctions.</p> <p><img src="https://camo.githubusercontent.com/6e0b322991cdb606579e438d3868de0bdd06c7d0/68747470733a2f2f7261776769746875622e636f6d2f4a756c69614d4c2f46696c6553746f726167652f6d61737465722f50656e616c747946756e6374696f6e732f756e69766172696174652e737667" alt="" /></p> <pre><code class="julia hljs">θ = rand(<span class=hljs-number >5</span>)  <span class=hljs-comment ># parameter vector</span>

p = L1Penalty()

value(p, θ)  <span class=hljs-comment ># sum(abs, θ)</span>
grad(p, θ)   <span class=hljs-comment ># the gradient, sign.(θ)</span>
prox(p, θ, <span class=hljs-number >.1</span>)  <span class=hljs-comment ># proximal mapping (soft-thresholding) with step size .1</span></code></pre> <p>Let&#39;s change our gradient descent algorithm to proximal gradient method:</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> g(l::Loss, pen::Penalty, x::<span class=hljs-built_in >Matrix</span>, y::<span class=hljs-built_in >Vector</span>; maxit=<span class=hljs-number >20</span>, s=<span class=hljs-number >.5</span>, λ=<span class=hljs-number >.1</span>)
    n, p = size(x)
    β = zeros(p)
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:maxit
        β = prox(pen, β - (s / n) * x&#x27; * deriv(l, y, x * β), s * λ)
    <span class=hljs-keyword >end</span>
    β
<span class=hljs-keyword >end</span></code></pre> <p>We can now do proximal gradient method on arbitrary loss/penalty combinations because multiple dispatch is amazing:</p> <pre><code class="julia hljs">julia&gt; g(L2DistLoss(), L1Penalty(), x, y; λ = <span class=hljs-number >.4</span>)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.789894</span>
 <span class=hljs-number >1.80736</span>
 <span class=hljs-number >2.81209</span>

julia&gt; g(L1DistLoss(), L1Penalty(), x, y; λ = <span class=hljs-number >.4</span>)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.0</span>
 <span class=hljs-number >0.464488</span>
 <span class=hljs-number >1.5998</span>

julia&gt; g(HuberLoss(<span class=hljs-number >2.</span>), L1Penalty(), x, y; λ = <span class=hljs-number >.4</span>)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.525633</span>
 <span class=hljs-number >1.57115</span>
 <span class=hljs-number >2.57907</span></code></pre> <h1 id=takeaway ><a href="#takeaway" class=header-anchor >Takeaway</a></h1> <p>These two packages create a consistent &quot;grammar&quot; for losses and regularization. Julia&#39;s multiple dispatch then allows us to write general algorithms like the proximal gradient method example. This paves the way for machine learning experimentation that is unavailable in any other language that I know of.</p> <div class=page-foot > &copy Josh Day. Last modified: August 16, 2023. Powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>. </div> </div> </div>