<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } @media (min-width: 768px) { .sidebar-sticky {position: relative} } h5 { color:darkgrey } .headshot { width: 10rem; border: 4px solid white; border-radius: 50%; } .product-img { height: 100px; width: auto; } </style> <title>JuliaML Basics</title> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-72795550-1', 'auto'); ga('send', 'pageview'); </script> <script src="/libs/lunr/lunr.min.js"></script> <script src="/libs/lunr/lunr_index.js"></script> <script src="/libs/lunr/lunrclient.min.js"></script> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img class=headshot  src="/assets/portrait.jpg"> <h1><a href="/">Dr. Josh Day</a></h1> </div> <br> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/">Home</a> <a class="sidebar-nav-item active" href="/blog/">Blog</a> </nav> <p style="font-size: .8em; padding-right: 10px;">I am a Researcher/Developer living in Carrboro, NC. When I'm not coding, I'm probably playing ultimate.</p> <br> <form id=lunrSearchForm  name=lunrSearchForm > <input class=search-input  name=q  placeholder="Search my site" type=text > <br> <input class=btn  type=submit  value=Search  formaction="/search/index.html"> </form> </div> </div> <div class="content container"> <div class=franklin-content ><h1 id=juliaml_basics ><a href="#juliaml_basics">JuliaML Basics</a></h1> <img src="https://avatars3.githubusercontent.com/u/15799035?v=3&s=200" style="width: 20%; margin:auto; border-radius: 5px"> <p><a href="https://github.com/JuliaML">JuliaML</a> is a GitHub organization dedicated to building tools for machine learning in Julia. This post serves as an introduction to some of the building blocks which JuliaML provides. The two packages I&#39;ll discuss here are:</p> <ul> <li><p><a href="https://github.com/JuliaML/LossFunctions.jl">LossFunctions.jl</a></p> <li><p><a href="https://github.com/JuliaML/PenaltyFunctions.jl">PenaltyFunctions.jl</a></p> </ul> <p>I&#39;m assuming you have a little background in statistics/machine learning and an objective function such as</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><mi mathvariant=normal >_</mi><msup><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msup><mi>f</mi><mi mathvariant=normal >_</mi><mi>i</mi><mo stretchy=false >(</mo><mi>β</mi><mo stretchy=false >)</mo><mo>+</mo><mo>∑</mo><mi mathvariant=normal >_</mi><msup><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></msup><mi>λ</mi><mi mathvariant=normal >_</mi><mi>j</mi><mi>J</mi><mo stretchy=false >(</mo><mi>β</mi><mi mathvariant=normal >_</mi><mi>j</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">\frac{1}{n}\sum\_{i=1}^n f\_i(\beta)+\sum\_{j=1}^p \lambda\_j J(\beta\_j)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.00744em;vertical-align:-0.686em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol large-op" style="position:relative;top:-0.000004999999999977245em;">∑</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class=mord ><span class="mord mathdefault">i</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mord >1</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathdefault">i</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1.6000100000000002em;vertical-align:-0.55001em;"></span><span class="mop op-symbol large-op" style="position:relative;top:-0.000004999999999977245em;">∑</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class=mord ><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mord >1</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span></span></span></span><span class="mord mathdefault">λ</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class=mclose >)</span></span></span></span></span> <p>is recognizable to you as a &quot;loss&quot; &#43; &quot;penalty&quot;.</p> <h1 id=lossfunctionsjl ><a href="#lossfunctionsjl">LossFunctions.jl</a></h1> <p>An interface for dealing with loss functions. Internally, most losses are defined as distance-based &#40;a function of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent=true ><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">\hat y-y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.69444em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=accent-body  style="left:-0.19444em;"><span class=mord >^</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.19444em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>&#41; or margin-based &#40;a function of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∗</mo><mover accent=true ><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">y * \hat y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6597200000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >∗</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.69444em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=accent-body  style="left:-0.19444em;"><span class=mord >^</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.19444em;"><span></span></span></span></span></span></span></span></span>&#41; where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> is the target and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent=true ><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.69444em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=accent-body  style="left:-0.19444em;"><span class=mord >^</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.19444em;"><span></span></span></span></span></span></span></span></span> is a predicted value.</p> <h4 id=distance-based_losses ><a href="#distance-based_losses">Distance-based losses</a></h4> <p><img src="https://camo.githubusercontent.com/80ae72e5878d98aacb0eed6863958c02fd73b1b3/68747470733a2f2f7261776769746875622e636f6d2f4a756c69614d4c2f46696c6553746f726167652f6d61737465722f4c6f737346756e6374696f6e732f64697374616e63652e737667" alt="" /></p> <h4 id=margin-based_losses ><a href="#margin-based_losses">Margin-based losses</a></h4> <p><img src="https://camo.githubusercontent.com/80dc81d308845dd34ff70a953aafffb30b2c5c3a/68747470733a2f2f7261776769746875622e636f6d2f4a756c69614d4c2f46696c6553746f726167652f6d61737465722f4c6f737346756e6374696f6e732f6d617267696e2e737667" alt="" /></p> <h3 id=example_usage ><a href="#example_usage">Example Usage</a></h3> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> LossFunctions

l = L1DistLoss()
value(l, <span class=hljs-number >.1</span>, <span class=hljs-number >.2</span>)  <span class=hljs-comment ># |.2 - .1|</span>
deriv(l, <span class=hljs-number >.1</span>, <span class=hljs-number >.2</span>)  <span class=hljs-comment ># sign(.2 - .1)</span>

y = randn(<span class=hljs-number >100</span>)
yhat = randn(<span class=hljs-number >100</span>)

value(l, y, yhat)  <span class=hljs-comment ># vector of value mapped to y[i], yhat[i]</span>
value(l, y, yhat, AvgMode.Sum())  <span class=hljs-comment ># sum(value(l, y, yhat)), but better</span>
value(l, y, yhat, AvgModel.Mean()) <span class=hljs-comment ># mean(value(l, y, yhat)), but better</span></code></pre> <h4 id=naive_gradient_descent_algorithm ><a href="#naive_gradient_descent_algorithm">Naive Gradient Descent Algorithm</a></h4> <p>Assume we want to use a linear transformation so that our prediction of a vector <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mi>β</mi></mrow><annotation encoding="application/x-tex">X\beta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span>.</p> <p>Our loss function looks like</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><mi mathvariant=normal >_</mi><msup><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msup><mi>f</mi><mo stretchy=false >(</mo><mi>y</mi><mi mathvariant=normal >_</mi><mi>i</mi><mo separator=true >,</mo><mi>x</mi><mi mathvariant=normal >_</mi><msup><mi>i</mi><mi>T</mi></msup><mi>β</mi><mo stretchy=false >)</mo><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> \frac{1}{n}\sum\_{i=1}^n f(y\_i, x\_i^T\beta), </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.00744em;vertical-align:-0.686em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol large-op" style="position:relative;top:-0.000004999999999977245em;">∑</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class=mord ><span class="mord mathdefault">i</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mord >1</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathdefault">i</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class="mord mathdefault">i</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mclose >)</span><span class=mpunct >,</span></span></span></span></span> <p>with gradient</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mi>T</mi></msup><mo stretchy=false >[</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mi>f</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup><mo stretchy=false >(</mo><mi>y</mi><mi mathvariant=normal >_</mi><mi>i</mi><mo separator=true >,</mo><mi>x</mi><mi mathvariant=normal >_</mi><msup><mi>i</mi><mi>T</mi></msup><mi>β</mi><mo stretchy=false >)</mo><mo stretchy=false >]</mo><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> X^T[\frac{1}{n}\sum_{i=1}^n f&#x27;(y\_i, x\_i^T\beta)]. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.929066em;vertical-align:-1.277669em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class=mopen >[</span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.277669em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=mord  style="margin-right:0.02778em;">_</span><span class="mord mathdefault">i</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class=mord  style="margin-right:0.02778em;">_</span><span class=mord ><span class="mord mathdefault">i</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mclose >)</span><span class=mclose >]</span><span class=mord >.</span></span></span></span></span> <p>We can implement a naive, inefficient gradient descent algorithm as:</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> f(l::Loss, x::<span class=hljs-built_in >Matrix</span>, y::<span class=hljs-built_in >Vector</span>; maxit=<span class=hljs-number >20</span>, s=<span class=hljs-number >.5</span>)
    n, p = size(x)
    β = zeros(p)
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:maxit
        β -= (s / n) * x&#x27; * deriv(l, y, x * β)
    <span class=hljs-keyword >end</span>
    β
<span class=hljs-keyword >end</span></code></pre> <p>This automatically works with whatever loss function I provide because multiple dispatch is amazing:</p> <pre><code class="julia hljs"><span class=hljs-comment ># make some fake data</span>
x = randn(<span class=hljs-number >1000</span>, <span class=hljs-number >3</span>)
y = x * [<span class=hljs-number >1.0</span>, <span class=hljs-number >2.0</span>, <span class=hljs-number >3.0</span>] + randn(<span class=hljs-number >1000</span>)</code></pre> <pre><code class="julia hljs">julia&gt; f(L2DistLoss(), x, y)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.966367</span>
 <span class=hljs-number >2.05046</span>
 <span class=hljs-number >2.94227</span>

julia&gt; f(L1DistLoss(), x, y)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >1.00185</span>
 <span class=hljs-number >2.00302</span>
 <span class=hljs-number >2.95002</span>

julia&gt; f(HuberLoss(<span class=hljs-number >2.</span>), x, y)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.967642</span>
 <span class=hljs-number >2.0485</span>
 <span class=hljs-number >2.94429</span></code></pre> <h1 id=penaltyfunctionsjl ><a href="#penaltyfunctionsjl">PenaltyFunctions.jl</a></h1> <p>An interface for penalty/regularization functions. It follows similar conventions to LossFunctions.</p> <p><img src="https://camo.githubusercontent.com/6e0b322991cdb606579e438d3868de0bdd06c7d0/68747470733a2f2f7261776769746875622e636f6d2f4a756c69614d4c2f46696c6553746f726167652f6d61737465722f50656e616c747946756e6374696f6e732f756e69766172696174652e737667" alt="" /></p> <pre><code class="julia hljs">θ = rand(<span class=hljs-number >5</span>)  <span class=hljs-comment ># parameter vector</span>

p = L1Penalty()

value(p, θ)  <span class=hljs-comment ># sum(abs, θ)</span>
grad(p, θ)   <span class=hljs-comment ># the gradient, sign.(θ)</span>
prox(p, θ, <span class=hljs-number >.1</span>)  <span class=hljs-comment ># proximal mapping (soft-thresholding) with step size .1</span></code></pre> <p>Let&#39;s change our gradient descent algorithm to proximal gradient method:</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> g(l::Loss, pen::Penalty, x::<span class=hljs-built_in >Matrix</span>, y::<span class=hljs-built_in >Vector</span>; maxit=<span class=hljs-number >20</span>, s=<span class=hljs-number >.5</span>, λ=<span class=hljs-number >.1</span>)
    n, p = size(x)
    β = zeros(p)
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:maxit
        β = prox(pen, β - (s / n) * x&#x27; * deriv(l, y, x * β), s * λ)
    <span class=hljs-keyword >end</span>
    β
<span class=hljs-keyword >end</span></code></pre> <p>We can now do proximal gradient method on arbitrary loss/penalty combinations because multiple dispatch is amazing:</p> <pre><code class="julia hljs">julia&gt; g(L2DistLoss(), L1Penalty(), x, y; λ = <span class=hljs-number >.4</span>)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.789894</span>
 <span class=hljs-number >1.80736</span>
 <span class=hljs-number >2.81209</span>

julia&gt; g(L1DistLoss(), L1Penalty(), x, y; λ = <span class=hljs-number >.4</span>)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.0</span>
 <span class=hljs-number >0.464488</span>
 <span class=hljs-number >1.5998</span>

julia&gt; g(HuberLoss(<span class=hljs-number >2.</span>), L1Penalty(), x, y; λ = <span class=hljs-number >.4</span>)
<span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >0.525633</span>
 <span class=hljs-number >1.57115</span>
 <span class=hljs-number >2.57907</span></code></pre> <h1 id=takeaway ><a href="#takeaway">Takeaway</a></h1> <p>These two packages create a consistent &quot;grammar&quot; for losses and regularization. Julia&#39;s multiple dispatch then allows us to write general algorithms like the proximal gradient method example. This paves the way for machine learning experimentation that is unavailable in any other language that I know of.</p> <div class=page-foot > <div class=copyright > &copy; Josh Day. Last modified: September 21, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>. </div> </div> <script async defer src="https://buttons.github.io/buttons.js"></script></div> </div>